{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d168062",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "\n",
    "MONGO_URI = \"mongodb://Yacin09:LBV2026+@atlas-sql-669652cef094e500b8eaee60-2eo4m.a.query.mongodb.net/?ssl=true&authSource=admin\"\n",
    "DB_NAME = \"ticketing_db\"\n",
    "\n",
    "EXCEL_TO_COLLECTION = {\n",
    "    \"agents.xlsx\": \"agents\",\n",
    "    \"tickets.xlsx\": \"tickets\",\n",
    "    \"thematiques.xlsx\": \"thematiques\",\n",
    "    \"magasins.xlsx\": \"magasins\",\n",
    "    \"canaux.xlsx\": \"canaux\"\n",
    "}\n",
    "\n",
    "client = MongoClient(MONGO_URI)\n",
    "db = client[DB_NAME]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8121f0fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Imported 5 documents into 'agents'\n",
      "âœ… Imported 2 documents into 'tickets'\n",
      "âœ… Imported 5 documents into 'canaux'\n",
      "ðŸŽ¯ Import completed.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "\n",
    "\n",
    "EXCEL_FILE = \"Tickets Support.xlsx\"\n",
    "\n",
    "SHEET_TO_COLLECTION = {\n",
    "    \"agents\": \"agents\",\n",
    "    \"tickets\": \"tickets\",\n",
    "    \"canal\": \"canaux\"\n",
    "}\n",
    "\n",
    "client = MongoClient(MONGO_URI)\n",
    "db = client[DB_NAME]\n",
    "\n",
    "def import_sheet(sheet_name, collection_name):\n",
    "    df = pd.read_excel(EXCEL_FILE, sheet_name=sheet_name)\n",
    "    df = df.where(pd.notnull(df), None)  \n",
    "    records = df.to_dict(orient=\"records\")\n",
    "\n",
    "    if not records:\n",
    "        print(f\"âš  No data found in sheet '{sheet_name}'\")\n",
    "        return\n",
    "\n",
    "    db[collection_name].delete_many({})\n",
    "    db[collection_name].insert_many(records)\n",
    "    print(f\"âœ… Imported {len(records)} documents into '{collection_name}'\")\n",
    "\n",
    "for sheet, collection in SHEET_TO_COLLECTION.items():\n",
    "    import_sheet(sheet, collection)\n",
    "\n",
    "print(\"ðŸŽ¯ Import completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e996e717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… 23 lignes importÃ©es dans 'magasins' depuis CSV (magasins.csv)\n",
      "âœ… 68 lignes importÃ©es dans 'thematiques' depuis CSV (thematiques.csv)\n",
      "ðŸŽ¯ Import terminÃ©.\n"
     ]
    }
   ],
   "source": [
    "CSV_MAGASINS = \"magasins.csv\"\n",
    "CSV_THEMATIQUES = \"thematiques.csv\"\n",
    "\n",
    "CSV_TO_COLLECTION = {\n",
    "    CSV_MAGASINS: \"magasins\",\n",
    "    CSV_THEMATIQUES: \"thematiques\"\n",
    "}\n",
    "\n",
    "def import_csv(file_path, collection_name):\n",
    "    df = pd.read_csv(file_path, sep=\";\")\n",
    "    df = df.where(pd.notnull(df), None)\n",
    "    records = df.to_dict(orient=\"records\")\n",
    "    db[collection_name].delete_many({})\n",
    "    db[collection_name].insert_many(records)\n",
    "    print(f\"âœ… {len(records)} lignes importÃ©es dans '{collection_name}' depuis CSV ({file_path})\")\n",
    "\n",
    "\n",
    "for csv_file, collection in CSV_TO_COLLECTION.items():\n",
    "    import_csv(csv_file, collection)\n",
    "\n",
    "print(\"ðŸŽ¯ Import terminÃ©.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef452ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "918 documents insÃ©rÃ©s dans la collection 'tickets'.\n"
     ]
    }
   ],
   "source": [
    "# import_tickets.py\n",
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "\n",
    "MONGO_URI = \"mongodb://Yacin09:LBV2026+@atlas-sql-669652cef094e500b8eaee60-2eo4m.a.query.mongodb.net/?ssl=true&authSource=admin\"\n",
    "DB_NAME = \"ticketing_db\"\n",
    "COLLECTION_NAME = \"tickets\"\n",
    "CSV_FILE = \"BAse Tickets.csv\"  \n",
    "client = MongoClient(MONGO_URI)\n",
    "db = client[DB_NAME]\n",
    "collection = db[COLLECTION_NAME]\n",
    "df = pd.read_csv(CSV_FILE, encoding=\"ISO-8859-1\", sep=\";\", quotechar='\"')\n",
    "data = df.to_dict(orient=\"records\")\n",
    "if data:\n",
    "    collection.insert_many(data)\n",
    "    print(f\"{len(data)} documents insÃ©rÃ©s dans la collection '{COLLECTION_NAME}'.\")\n",
    "else:\n",
    "    print(\"Aucune donnÃ©e trouvÃ©e dans le CSV.\")\n",
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd6c1e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "918 documents insÃ©rÃ©s.\n",
      "Compteur rebased Ã  918. Prochain ticket sera 919.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pymongo import MongoClient, errors\n",
    "from datetime import datetime\n",
    "\n",
    "# ====== CONFIG ======\n",
    "MONGO_URI = \"mongodb://Yacin09:LBV2026+@atlas-sql-669652cef094e500b8eaee60-2eo4m.a.query.mongodb.net/?ssl=true&authSource=admin\"\n",
    "DB_NAME = \"ticketing_db\"\n",
    "COLLECTION = \"tickets\"\n",
    "CSV_FILE = \"BAse Tickets.csv\"\n",
    "KEEP_EXISTING_IDS = True        \n",
    "# ====================\n",
    "\n",
    "EXPECTED = [\n",
    "    'id','date_creation','agent','nom_prenom','id_client','num_cmd','canal',\n",
    "    'thematique','famille','sous_famille','categorie','sous_categorie','action',\n",
    "    'traitement','si_exceptionnel','code_promo','prix_pdts','mnt_commande','mnt_rembour',\n",
    "    'mnt_gestco','total_code_promo','retour_magasin','commentaires',\n",
    "    'date_cloture','cloture_by','statut','magasin','num_magasin','ville','bu','region','dr','dm'\n",
    "]\n",
    "\n",
    "HEADER_MAP = {\n",
    "    \"sous famille\": \"sous_famille\",\n",
    "    \"sous_famille\": \"sous_famille\",\n",
    "    \"catÃ©gorie\": \"categorie\",\n",
    "    \"sous categorie\": \"sous_categorie\",\n",
    "    \"sous catÃ©gorie\": \"sous_categorie\",\n",
    "    \"actions\": \"action\",\n",
    "}\n",
    "\n",
    "MONEY_COLS = [\"prix_pdts\",\"mnt_commande\",\"mnt_rembour\",\"mnt_gestco\",\"total_code_promo\"]\n",
    "\n",
    "def parse_date(val):\n",
    "    \"\"\"Return 'YYYY-MM-DD HH:MM:SS' or '' if not parseable.\"\"\"\n",
    "    if pd.isna(val): \n",
    "        return \"\"\n",
    "    s = str(val).strip()\n",
    "    if not s or s.lower() in {\"none\",\"nan\",\"nat\"}:\n",
    "        return \"\"\n",
    "    # Try common formats (French day-first, with/without seconds)\n",
    "    for fmt in (\"%d/%m/%Y %H:%M:%S\", \"%d/%m/%Y %H:%M\", \"%Y-%m-%d %H:%M:%S\", \"%Y-%m-%d\"):\n",
    "        try:\n",
    "            return datetime.strptime(s, fmt).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        except ValueError:\n",
    "            pass\n",
    "    # Fallback: let pandas try with dayfirst\n",
    "    try:\n",
    "        dt = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
    "        if pd.isna(dt): \n",
    "            return \"\"\n",
    "        return dt.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    except Exception:\n",
    "        return \"\"\n",
    "\n",
    "def clean_money(val):\n",
    "    \"\"\"Handle '', None, '_', '-', '12,3', etc. -> float\"\"\"\n",
    "    if pd.isna(val):\n",
    "        return 0.0\n",
    "    s = str(val).strip()\n",
    "    if s in {\"\", \"_\", \"-\", \"None\"}:\n",
    "        return 0.0\n",
    "    s = s.replace(\",\", \".\")\n",
    "    try:\n",
    "        return float(s)\n",
    "    except ValueError:\n",
    "        return 0.0\n",
    "\n",
    "def norm_text(val):\n",
    "    if pd.isna(val): \n",
    "        return \"\"\n",
    "    return str(val).replace(\"\\u00A0\",\" \").strip()\n",
    "\n",
    "def main():\n",
    "    # 1) Read CSV with French separators if needed\n",
    "    df = pd.read_csv(CSV_FILE, encoding=\"ISO-8859-1\", sep=\";\", quotechar='\"')\n",
    "\n",
    "    # 2) Normalize headers\n",
    "    cols = []\n",
    "    for c in df.columns:\n",
    "        base = norm_text(c)\n",
    "        base_low = base.lower().strip()\n",
    "        base_low = base_low.replace(\"Ã©\",\"e\").replace(\"Ã¨\",\"e\").replace(\"Ãª\",\"e\")\n",
    "        mapped = HEADER_MAP.get(base_low, base_low)\n",
    "        cols.append(mapped)\n",
    "    df.columns = cols\n",
    "    # 3) Ensure all expected columns exist\n",
    "    for col in EXPECTED:\n",
    "        if col not in df.columns:\n",
    "            df[col] = \"\"\n",
    "\n",
    "    # 4) Trim text fields\n",
    "    for c in df.columns:\n",
    "        if c not in MONEY_COLS and c not in (\"date_creation\",\"date_cloture\",\"id\"):\n",
    "            df[c] = df[c].apply(norm_text)\n",
    "\n",
    "    # 5) Dates\n",
    "    df[\"date_creation\"] = df[\"date_creation\"].apply(parse_date)\n",
    "    if \"date_cloture\" in df.columns:\n",
    "        df[\"date_cloture\"] = df[\"date_cloture\"].apply(parse_date)\n",
    "\n",
    "    # 6) Money\n",
    "    for c in MONEY_COLS:\n",
    "        df[c] = df[c].apply(clean_money)\n",
    "\n",
    "    # 7) Statut normalization\n",
    "    df[\"statut\"] = df[\"statut\"]\n",
    "\n",
    "    # 8) IDs\n",
    "    if KEEP_EXISTING_IDS:\n",
    "        # Keep current id if numeric; blank -> NaN\n",
    "        def keep_numeric_or_nan(x):\n",
    "            s = norm_text(x)\n",
    "            return s if s.isdigit() else np.nan\n",
    "        df[\"id\"] = df[\"id\"].apply(keep_numeric_or_nan)\n",
    "        # weâ€™ll fill missing later from DB counter after insert (or drop them)\n",
    "    else:\n",
    "        # Regenerate contiguous 1..N\n",
    "        df[\"id\"] = range(1, len(df)+1)\n",
    "\n",
    "    # 9) Recompute total_code_promo if missing/zero\n",
    "    # (your app also recomputes on save, but set a sensible base)\n",
    "    needs_total = (df[\"total_code_promo\"] == 0) & ((df[\"mnt_rembour\"] != 0) | (df[\"mnt_gestco\"] != 0))\n",
    "    df.loc[needs_total, \"total_code_promo\"] = df[\"mnt_rembour\"] + df[\"mnt_gestco\"]\n",
    "\n",
    "    # 10) Keep only expected columns and order\n",
    "    df = df[EXPECTED]\n",
    "\n",
    "    # 11) Connect to Mongo\n",
    "    client = MongoClient(MONGO_URI)\n",
    "    db = client[DB_NAME]\n",
    "    col = db[COLLECTION]\n",
    "\n",
    "    # 12) Index on id (unique)\n",
    "    try:\n",
    "        col.create_index(\"id\", unique=True)\n",
    "    except errors.OperationFailure:\n",
    "        pass\n",
    "\n",
    "    # 13) Insert\n",
    "    docs = df.to_dict(orient=\"records\")\n",
    "    # Remove rows with empty id when KEEP_EXISTING_IDS=True to avoid dup-key on None\n",
    "    if KEEP_EXISTING_IDS:\n",
    "        docs = [d for d in docs if str(d.get(\"id\",\"\")).isdigit()]\n",
    "\n",
    "    if not docs:\n",
    "        print(\"Aucune donnÃ©e prÃªte Ã  lâ€™insertion.\")\n",
    "    else:\n",
    "        try:\n",
    "            col.insert_many(docs, ordered=False)\n",
    "            print(f\"{len(docs)} documents insÃ©rÃ©s.\")\n",
    "        except errors.BulkWriteError as e:\n",
    "            # Continue even if some duplicates exist\n",
    "            dup = sum(1 for w in e.details.get(\"writeErrors\", []) if w.get(\"code\") == 11000)\n",
    "            ok = e.details.get(\"nInserted\", 0)\n",
    "            print(f\"Insertion partielle : {ok} insÃ©rÃ©s, {dup} doublons (ignorÃ©s).\")\n",
    "\n",
    "    # 14) Rebase the counter so next ticket = max(id) + 1\n",
    "    # counters: { _id:\"tickets\", seq:<int> }\n",
    "    max_id = 0\n",
    "    for r in col.find({}, {\"_id\":0, \"id\":1}):\n",
    "        s = str(r.get(\"id\",\"\")).strip()\n",
    "        if s.isdigit():\n",
    "            max_id = max(max_id, int(s))\n",
    "\n",
    "    counters = db[\"counters\"]\n",
    "    counters.update_one({\"_id\":\"tickets\"}, {\"$set\":{\"seq\": max_id}}, upsert=True)\n",
    "    print(f\"Compteur rebased Ã  {max_id}. Prochain ticket sera {max_id+1}.\")\n",
    "\n",
    "    client.close()\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
